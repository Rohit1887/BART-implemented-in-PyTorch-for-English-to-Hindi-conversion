{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5fb384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499f765",
   "metadata": {},
   "source": [
    "Find vocab size of the dataset\n",
    "\n",
    "https://github.com/huggingface/transformers/issues/4151\n",
    "\n",
    "https://stackoverflow.com/questions/73204460/how-to-pretrain-bart-using-custom-datasetnot-fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2150b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", \n",
    "                                          do_lower_case=False, use_fast=False, keep_accents=True)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db082db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_id = tokenizer._convert_token_to_id_with_added_voc(\"<s>\")\n",
    "eos_id = tokenizer._convert_token_to_id_with_added_voc(\"</s>\")\n",
    "pad_id = tokenizer._convert_token_to_id_with_added_voc(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b55a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tokenizer(\"I am a boy </s> <2en>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids \n",
    "\n",
    "out = tokenizer(\"<2hi> मैं  एक लड़का हूँ </s>\", add_special_tokens=False, return_tensors=\"pt\", padding=True).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f59093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  466,  1981,    80, 25573, 64001, 64004]])\n"
     ]
    }
   ],
   "source": [
    "print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e557ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[64006,   942,    43, 32720,  8384, 64001]])\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0abe7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[64006,   942,    43, 32720,  8384]])\n"
     ]
    }
   ],
   "source": [
    "print(out[:,0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2544632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  942,    43, 32720,  8384, 64001]])\n"
     ]
    }
   ],
   "source": [
    "print(out[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcafdac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs=model(input_ids=inp, decoder_input_ids=out[:,0:-1], labels=out[:,1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff1be60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7369, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d528541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5566,  0.2969,  0.5566,  ...,  0.7106, -0.0018, -0.9501],\n",
       "         [ 0.4918,  0.1316,  0.4917,  ...,  0.4986,  0.3004, -0.6960],\n",
       "         [ 0.7462,  0.7578,  0.7462,  ...,  0.5706, -1.1140, -0.2669],\n",
       "         [ 0.3260,  1.4900,  0.3260,  ..., -0.2245,  0.0107, -0.2596],\n",
       "         [ 0.2783,  1.5880,  0.2783,  ...,  0.1308,  0.2887,  0.0781]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs.logits\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2d432d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output=model.generate(inp, use_cache=True, num_beams=4, max_length=20, min_length=1, \n",
    "                            early_stopping=True, pad_token_id=pad_id, bos_token_id=bos_id, \n",
    "                            eos_token_id=eos_id, \n",
    "                            decoder_start_token_id=tokenizer._convert_token_to_id_with_added_voc(\"<2en>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7b28308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[64004,   466,  1981,    80, 25573, 64001]])\n"
     ]
    }
   ],
   "source": [
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac5ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 15:32:21.916176: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-02 15:32:21.916377: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-07-02 15:32:21.916388: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "decoded_output=tokenizer.decode(model_output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1692ed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a boy\n"
     ]
    }
   ],
   "source": [
    "print(decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900f7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
